#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”„å¬›è§’è‰²Webå¯¹è¯ç•Œé¢

åŸºäºStreamlitçš„ç”„å¬›è§’è‰²å¯¹è¯Webåº”ç”¨
å‚è€ƒ: https://github.com/KMnO4-zx/huanhuan-chat

ä½¿ç”¨æ–¹æ³•:
    streamlit run application/huanhuan_web.py
    streamlit run application/huanhuan_web.py --server.port 8501
"""

import os
import sys
import json
import requests
import streamlit as st
from pathlib import Path
from typing import List, Dict
import time
from datetime import datetime
import uuid

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥åé¦ˆå¤„ç†æ¨¡å—
from application.feedback_handler import FeedbackHandler

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Chat-å¬›å¬› - ç”„å¬›ä¼ è§’è‰²å¯¹è¯",
    page_icon="ğŸ‘¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

class HuanHuanWebApp:
    """
    ç”„å¬›Webåº”ç”¨
    """
    
    def __init__(self):
        self.ollama_host = "http://localhost:11434"
        self.model_name = "huanhuan-qwen"
        
        # åˆå§‹åŒ–åé¦ˆå¤„ç†å™¨
        self.feedback_handler = FeedbackHandler()
        
        # åˆå§‹åŒ–session state
        self.init_session_state()
    
    def init_session_state(self):
        """
        åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        """
        # å¯¹è¯å†å²
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # Ollamaè¿æ¥çŠ¶æ€
        if "ollama_connected" not in st.session_state:
            st.session_state.ollama_connected = False
        
        # å¯ç”¨æ¨¡å‹åˆ—è¡¨
        if "available_models" not in st.session_state:
            st.session_state.available_models = []
        
        # å½“å‰é€‰æ‹©çš„æ¨¡å‹
        if "selected_model" not in st.session_state:
            st.session_state.selected_model = None
        
        # ç”Ÿæˆå‚æ•°
        if "temperature" not in st.session_state:
            st.session_state.temperature = 0.7
        if "top_p" not in st.session_state:
            st.session_state.top_p = 0.9
        if "top_k" not in st.session_state:
            st.session_state.top_k = 40
        if "max_tokens" not in st.session_state:
            st.session_state.max_tokens = 256
        
        # å¯¹è¯å†å²è®°å½•
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
        
        # ä¼šè¯ID
        if 'session_id' not in st.session_state:
            st.session_state.session_id = str(uuid.uuid4())
        
        # å½“å‰å¯¹è¯çš„åé¦ˆçŠ¶æ€
        if 'current_feedback' not in st.session_state:
            st.session_state.current_feedback = {}
    
    def check_ollama_connection(self) -> bool:
        """
        æ£€æŸ¥OllamaæœåŠ¡è¿æ¥çŠ¶æ€
        """
        try:
            response = requests.get(f"{self.ollama_host}/api/tags", timeout=5)
            if response.status_code == 200:
                st.session_state.ollama_connected = True
                return True
        except requests.exceptions.RequestException:
            pass
        
        st.session_state.ollama_connected = False
        return False
    
    def get_available_models(self) -> List[str]:
        """
        è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
        """
        if not self.check_ollama_connection():
            return []
        
        try:
            response = requests.get(f"{self.ollama_host}/api/tags")
            if response.status_code == 200:
                data = response.json()
                models = [model['name'] for model in data['models']]
                st.session_state.available_models = models
                return models
        except Exception as e:
            st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        
        return []
    
    def chat_with_model(self, prompt: str, model: str) -> str:
        """
        ä¸æ¨¡å‹å¯¹è¯
        
        Args:
            prompt: ç”¨æˆ·è¾“å…¥
            model: æ¨¡å‹åç§°
            
        Returns:
            æ¨¡å‹å›å¤
        """
        try:
            payload = {
                "model": model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": st.session_state.temperature,
                    "top_p": st.session_state.top_p,
                    "top_k": st.session_state.top_k,
                    "num_predict": st.session_state.max_tokens
                }
            }
            
            response = requests.post(
                f"{self.ollama_host}/api/generate",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("response", "")
            else:
                return f"é”™è¯¯: HTTP {response.status_code}"
        except Exception as e:
            return f"è¯·æ±‚å¤±è´¥: {str(e)}"
    
    def save_chat_history(self):
        """
        ä¿å­˜èŠå¤©å†å²åˆ°æ–‡ä»¶
        """
        if not st.session_state.messages:
            return
        
        try:
            # åˆ›å»ºèŠå¤©å†å²ç›®å½•
            history_dir = Path(__file__).parent / "chat_history"
            history_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"huanhuan_chat_{timestamp}.json"
            filepath = history_dir / filename
            
            # ä¿å­˜èŠå¤©å†å²
            chat_data = {
                "session_id": st.session_state.session_id,
                "timestamp": timestamp,
                "messages": st.session_state.messages
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(chat_data, f, ensure_ascii=False, indent=2)
            
            st.success(f"èŠå¤©å†å²å·²ä¿å­˜: {filename}")
        except Exception as e:
            st.error(f"ä¿å­˜èŠå¤©å†å²å¤±è´¥: {e}")
    
    def render_sidebar(self):
        """
        æ¸²æŸ“ä¾§è¾¹æ 
        """
        with st.sidebar:
            st.title("ğŸ‘‘ Chat-å¬›å¬›")
            st.markdown("---")
            
            # è¿æ¥çŠ¶æ€
            if self.check_ollama_connection():
                st.success("ğŸŸ¢ OllamaæœåŠ¡å·²è¿æ¥")
            else:
                st.error("ğŸ”´ OllamaæœåŠ¡æœªè¿æ¥")
                st.info("è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
            
            # æ¨¡å‹é€‰æ‹©
            available_models = self.get_available_models()
            if available_models:
                st.session_state.selected_model = st.selectbox(
                    "é€‰æ‹©æ¨¡å‹",
                    options=available_models,
                    index=0 if st.session_state.selected_model is None else 
                          available_models.index(st.session_state.selected_model) 
                          if st.session_state.selected_model in available_models else 0
                )
            else:
                st.warning("æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹")
                st.session_state.selected_model = None
            
            st.markdown("---")
            
            # å‚æ•°è°ƒèŠ‚
            st.subheader("âš™ï¸ å‚æ•°è°ƒèŠ‚")
            st.session_state.temperature = st.slider(
                "Temperature", 0.0, 1.0, st.session_state.temperature, 0.1
            )
            st.session_state.top_p = st.slider(
                "Top-p", 0.0, 1.0, st.session_state.top_p, 0.1
            )
            st.session_state.top_k = st.slider(
                "Top-k", 1, 100, st.session_state.top_k, 1
            )
            st.session_state.max_tokens = st.slider(
                "æœ€å¤§ç”Ÿæˆé•¿åº¦", 50, 1000, st.session_state.max_tokens, 50
            )
            
            st.markdown("---")
            
            # åŠŸèƒ½æŒ‰é’®
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ’¾ ä¿å­˜å¯¹è¯"):
                    self.save_chat_history()
            
            with col2:
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
                    st.session_state.messages = []
                    st.session_state.session_id = str(uuid.uuid4())
                    st.rerun()
            
            # åé¦ˆç»Ÿè®¡
            st.markdown("---")
            st.subheader("ğŸ“Š åé¦ˆç»Ÿè®¡")
            feedback_stats = self.feedback_handler.get_feedback_stats()
            st.metric("æ€»åé¦ˆæ•°", feedback_stats['total_feedback'])
            st.metric("æ­£é¢åé¦ˆç‡", f"{feedback_stats['positive_rate']:.2%}")
            st.metric("å¹³å‡è¯„åˆ†", feedback_stats['avg_rating'])
    
    def render_feedback_section(self, message_index: int):
        """
        æ¸²æŸ“åé¦ˆéƒ¨åˆ†
        
        Args:
            message_index: æ¶ˆæ¯ç´¢å¼•
        """
        # è·å–æ¶ˆæ¯
        if message_index >= len(st.session_state.messages):
            return
        
        message = st.session_state.messages[message_index]
        if message['role'] != 'assistant':
            return
        
        # ç”Ÿæˆåé¦ˆç»„ä»¶çš„å”¯ä¸€é”®
        feedback_key = f"feedback_{message_index}"
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰åé¦ˆ
        if feedback_key in st.session_state.current_feedback:
            st.success("âœ… æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
            return
        
        # æ˜¾ç¤ºåé¦ˆç»„ä»¶
        st.markdown("---")
        st.markdown("#### è¯·å¯¹è¿™ä¸ªå›ç­”è¿›è¡Œè¯„ä»·ï¼š")
        
        # è¯„åˆ†
        rating = st.radio(
            "è¯„åˆ†",
            options=[("â­", 1), ("â­â­", 2), ("â­â­â­", 3), ("â­â­â­â­", 4), ("â­â­â­â­â­", 5)],
            format_func=lambda x: x[0],
            key=f"rating_{message_index}",
            horizontal=True
        )
        
        # è¯„è®º
        comment = st.text_area(
            "è¯¦ç»†è¯„è®ºï¼ˆå¯é€‰ï¼‰",
            key=f"comment_{message_index}",
            placeholder="æ‚¨è§‰å¾—è¿™ä¸ªå›ç­”æ€ä¹ˆæ ·ï¼Ÿæœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ"
        )
        
        # æäº¤æŒ‰é’®
        if st.button("æäº¤åé¦ˆ", key=f"submit_{message_index}"):
            if rating:
                # å‡†å¤‡åé¦ˆæ•°æ®
                user_message = st.session_state.messages[message_index-1] if message_index > 0 else {"content": ""}
                
                feedback_data = {
                    "session_id": st.session_state.session_id,
                    "model_name": st.session_state.selected_model or "unknown",
                    "user_input": user_message.get("content", ""),
                    "model_response": message.get("content", ""),
                    "rating": rating[1],  # è·å–è¯„åˆ†å€¼
                    "comment": comment
                }
                
                # ä¿å­˜åé¦ˆ
                if self.feedback_handler.save_feedback(feedback_data):
                    # è®°å½•å·²æäº¤åé¦ˆ
                    st.session_state.current_feedback[feedback_key] = True
                    st.success("âœ… æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
                    st.rerun()
                else:
                    st.error("âŒ æäº¤åé¦ˆå¤±è´¥ï¼Œè¯·é‡è¯•")
    
    def render_chat_interface(self):
        """
        æ¸²æŸ“èŠå¤©ç•Œé¢
        """
        # æ˜¾ç¤ºèŠå¤©å†å²
        for i, message in enumerate(st.session_state.messages):
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                # å¦‚æœæ˜¯åŠ©æ‰‹å›å¤ï¼Œæ˜¾ç¤ºåé¦ˆéƒ¨åˆ†
                if message["role"] == "assistant":
                    self.render_feedback_section(i)
        
        # ç”¨æˆ·è¾“å…¥
        if prompt := st.chat_input("ä¸ç”„å¬›å¯¹è¯..."):
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # è·å–æ¨¡å‹å›å¤
            if st.session_state.selected_model:
                with st.chat_message("assistant"):
                    with st.spinner("ç”„å¬›æ­£åœ¨æ€è€ƒ..."):
                        response = self.chat_with_model(prompt, st.session_state.selected_model)
                    
                    st.markdown(response)
                    
                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    
                    # æ˜¾ç¤ºåé¦ˆéƒ¨åˆ†
                    self.render_feedback_section(len(st.session_state.messages) - 1)
            else:
                st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
    
    def render_feedback_analysis(self):
        """
        æ¸²æŸ“åé¦ˆåˆ†æé¡µé¢
        """
        st.title("ğŸ“ˆ åé¦ˆåˆ†æ")
        
        # è·å–åé¦ˆç»Ÿè®¡æ•°æ®
        feedback_stats = self.feedback_handler.get_feedback_stats()
        
        # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»åé¦ˆæ•°", feedback_stats['total_feedback'])
        with col2:
            st.metric("æ­£é¢åé¦ˆ", feedback_stats['positive_feedback'])
        with col3:
            st.metric("è´Ÿé¢åé¦ˆ", feedback_stats['negative_feedback'])
        with col4:
            st.metric("å¹³å‡è¯„åˆ†", feedback_stats['avg_rating'])
        
        st.progress(feedback_stats['positive_rate'], 
                   f"æ­£é¢åé¦ˆç‡: {feedback_stats['positive_rate']:.2%}")
        
        # æŒ‰æ¨¡å‹åˆ†ç»„çš„ç»Ÿè®¡
        st.subheader("å„æ¨¡å‹åé¦ˆç»Ÿè®¡")
        model_stats = self.feedback_handler.get_feedback_by_model()
        
        if model_stats:
            for model_name, stats in model_stats.items():
                with st.expander(f"ğŸ¤– {model_name}"):
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("åé¦ˆæ•°", stats['stats']['total'])
                    with col2:
                        st.metric("æ­£é¢åé¦ˆ", stats['stats']['positive'])
                    with col3:
                        st.metric("è´Ÿé¢åé¦ˆ", stats['stats']['negative'])
                    with col4:
                        st.metric("å¹³å‡è¯„åˆ†", stats['stats']['avg_rating'])
        else:
            st.info("æš‚æ— æ¨¡å‹åé¦ˆæ•°æ®")
        
        # æœ€è¿‘åé¦ˆ
        st.subheader("æœ€è¿‘åé¦ˆ")
        recent_feedback = self.feedback_handler.get_recent_feedback(10)
        
        if recent_feedback:
            for feedback in recent_feedback:
                with st.expander(f"â­ {feedback.get('rating', 0)}æ˜Ÿ - {feedback.get('timestamp', '')}"):
                    st.markdown(f"**æ¨¡å‹**: {feedback.get('model_name', 'unknown')}")
                    st.markdown(f"**ç”¨æˆ·è¾“å…¥**: {feedback.get('user_input', '')}")
                    st.markdown(f"**æ¨¡å‹å›å¤**: {feedback.get('model_response', '')}")
                    if feedback.get('comment'):
                        st.markdown(f"**è¯„è®º**: {feedback.get('comment', '')}")
        else:
            st.info("æš‚æ— åé¦ˆæ•°æ®")
    
    def render_training_data_export(self):
        """
        æ¸²æŸ“è®­ç»ƒæ•°æ®å¯¼å‡ºé¡µé¢
        """
        st.title("ğŸ“¤ è®­ç»ƒæ•°æ®å¯¼å‡º")
        
        st.markdown("""
        æœ¬é¡µé¢å…è®¸æ‚¨å°†ç”¨æˆ·æ­£é¢åé¦ˆå¯¼å‡ºä¸ºè®­ç»ƒæ•°æ®ï¼Œç”¨äºæ¨¡å‹çš„æŒç»­ä¼˜åŒ–ã€‚
        åªæœ‰è¯„åˆ†4æ˜ŸåŠä»¥ä¸Šçš„åé¦ˆä¼šè¢«å¯¼å‡ºã€‚
        """)
        
        # è·å–åé¦ˆç»Ÿè®¡æ•°æ®
        feedback_stats = self.feedback_handler.get_feedback_stats()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ€»åé¦ˆæ•°", feedback_stats['total_feedback'])
        with col2:
            st.metric("å¯ç”¨äºè®­ç»ƒçš„åé¦ˆæ•°", 
                     sum(1 for f in self.feedback_handler.load_feedback() if f.get('rating', 0) >= 4))
        
        # å¯¼å‡ºé€‰é¡¹
        st.subheader("å¯¼å‡ºè®¾ç½®")
        output_filename = st.text_input("è¾“å‡ºæ–‡ä»¶å", "user_feedback_training_data.jsonl")
        
        # å¯¼å‡ºæŒ‰é’®
        if st.button("å¯¼å‡ºè®­ç»ƒæ•°æ®"):
            try:
                # å¯¼å‡ºæ•°æ®
                training_data = self.feedback_handler.export_feedback_for_training(
                    output_file=str(Path(__file__).parent.parent / "data" / output_filename)
                )
                
                st.success(f"âœ… æˆåŠŸå¯¼å‡º {len(training_data)} æ¡è®­ç»ƒæ•°æ®åˆ° {output_filename}")
                
                # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
                if training_data:
                    st.subheader("å¯¼å‡ºæ•°æ®ç¤ºä¾‹")
                    for i, item in enumerate(training_data[:3]):
                        st.markdown(f"**ç¤ºä¾‹ {i+1}:**")
                        st.json(item)
            except Exception as e:
                st.error(f"å¯¼å‡ºå¤±è´¥: {e}")
    
    def run(self):
        """
        è¿è¡Œåº”ç”¨
        """
        # é¡µé¢é€‰æ‹©
        page = st.sidebar.radio("é¡µé¢å¯¼èˆª", ["ğŸ’¬ å¯¹è¯", "ğŸ“ˆ åé¦ˆåˆ†æ", "ğŸ“¤ è®­ç»ƒæ•°æ®å¯¼å‡º"])
        
        if page == "ğŸ’¬ å¯¹è¯":
            self.render_sidebar()
            self.render_chat_interface()
        elif page == "ğŸ“ˆ åé¦ˆåˆ†æ":
            self.render_feedback_analysis()
        elif page == "ğŸ“¤ è®­ç»ƒæ•°æ®å¯¼å‡º":
            self.render_training_data_export()


def main():
    """
    ä¸»å‡½æ•°
    """
    app = HuanHuanWebApp()
    app.run()


if __name__ == "__main__":
    main()