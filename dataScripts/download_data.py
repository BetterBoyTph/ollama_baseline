#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”„å¬›ä¼ æ•°æ®é›†ä¸‹è½½è„šæœ¬

ä»GitHubä¸‹è½½è®­ç»ƒæ•°æ®

ä½¿ç”¨æ–¹æ³•:
    python scripts/download_data.py
"""

import requests
from pathlib import Path
from tqdm import tqdm
from loguru import logger
import sys

class HuanHuanDataDownloader:
    """
    ç”„å¬›ä¼ æ•°æ®ä¸‹è½½å™¨
    """
    
    def __init__(self, data_dir: str = None):
        # å¦‚æœæœªæŒ‡å®šæ•°æ®ç›®å½•ï¼Œåˆ™ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„dataç›®å½•
        if data_dir is None:
            # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶çº§ç›®å½•ä½œä¸ºé¡¹ç›®æ ¹ç›®å½•
            script_dir = Path(__file__).parent
            project_root = script_dir.parent
            self.data_dir = project_root / "data"
        else:
            self.data_dir = Path(data_dir)
            
        self.raw_dir = self.data_dir / "raw"
        
        # åˆ›å»ºç›®å½•
        self.raw_dir.mkdir(parents=True, exist_ok=True)
        
        # æ•°æ®æºURL
        self.base_url = "https://raw.githubusercontent.com/datawhalechina/self-llm/master/dataset"
        
        # æ•°æ®æ–‡ä»¶
        self.data_file = "huanhuan.json"
    
    def download_file(self, url: str, save_path: Path, description: str = "") -> bool:
        """
        ä¸‹è½½æ–‡ä»¶
        """
        try:
            logger.info(f"å¼€å§‹ä¸‹è½½: {description or url}")
            
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(save_path, 'wb') as f:
                with tqdm(total=total_size, unit='B', unit_scale=True, desc=description) as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))
            
            logger.info(f"ä¸‹è½½å®Œæˆ: {save_path}")
            return True
            
        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥ {url}: {e}")
            return False
    
    def download_data(self) -> bool:
        """
        ä¸‹è½½è®­ç»ƒæ•°æ®
        """
        logger.info("å¼€å§‹ä¸‹è½½ç”„å¬›ä¼ æ•°æ®é›†...")
        
        url = f"{self.base_url}/{self.data_file}"
        save_path = self.raw_dir / self.data_file
        
        return self.download_file(url, save_path, "ç”„å¬›ä¼ è®­ç»ƒæ•°æ®")

    def run(self) -> bool:
        """
        æ‰§è¡Œæ•°æ®ä¸‹è½½
        """
        if self.download_data():
            logger.info("ğŸ‰ æ•°æ®ä¸‹è½½å®Œæˆï¼")
            logger.info(f"ğŸ“ æ•°æ®ä¿å­˜åœ¨: {self.data_dir}")
            logger.info("ğŸ“ æ¥ä¸‹æ¥å¯ä»¥è¿è¡Œ: python training/huanhuan_data_prepare.py")
            return True
        else:
            logger.error("âŒ æ•°æ®ä¸‹è½½å¤±è´¥")
            return False
    
def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description="ç”„å¬›ä¼ æ•°æ®ä¸‹è½½è„šæœ¬")
    parser.add_argument(
        "--data-dir",
        help="æ•°æ®å­˜å‚¨ç›®å½• (é»˜è®¤: é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„dataç›®å½•)"
    )
    
    args = parser.parse_args()
    
    downloader = HuanHuanDataDownloader(data_dir=args.data_dir)
    
    if not downloader.run():
        sys.exit(1)

if __name__ == "__main__":
    main()